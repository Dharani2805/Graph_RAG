1. generate_data 
    Input: source directory
    Output: JSON with entities and relationships

2. kg_construct
    Input: JSON
    Output: populate Noe4j database 

3. GraphRAG
# graph_embeddings.generate_embeddings()
# graph_embeddings.create_vector_index()
    Generate Embedding for each node
    Go through each and every node, and collect the connected nodes and their relationships as sentences
    Create Embeddings for those sentences
    Create Vector Index for Embedding
#graph_embeddings.get_response()
    Input: Question
    Output: Answer
    Methodology: convert query to embedding and do similarity search to retrieve top k nodes, and use it to provide answer - cosine similarity.
    G-Retriever: Retrieve sub-graph, convert subgraph to embedding and pass it as input arguments to LLM to get answer
    https://github.com/XiaoxinHe/G-Retriever/tree/main

#NLQ -> get_response()
    Input: Question
    Output: Answer
    Methodology: It converts question to CQL and retrieve the data from Neo4j, use that to give an answer.

4. RAG


5. graphQA -> streamlit
streamlit run graphQA.py
    


{'entity': 'Subject', 'Relationship': 'predicate', 'entity': 'object'}




<output>[{'Food': 'Sugary drinks', 'Relationship': 'worsens', 'Disease': 'Diabetes'},
{'Food': 'Sugary drinks', 'Relationship': 'contains', 'Nutrients': 'Carbohydrates'},
{'Food': 'egg', 'Relationship': 'good for', 'Health': 'Brain'}]<output>




docker run \
    -p 7474:7474 -p 7687:7687 \
    -v $PWD/data:/data -v $PWD/plugins:/plugins \
    --name neo4j-apoc \
    -e NEO4J_apoc_export_file_enabled=true \
    -e NEO4J_apoc_import_file_enabled=true \
    -e NEO4J_apoc_import_file_use__neo4j__config=true \
    -e NEO4JLABS_PLUGINS=\[\"apoc\"\] \
    --env NEO4J_AUTH=neo4j/qwerty_102030 \
    neo4j

CALL db.schema.visualization()

MATCH (n)-[r]->(m)
RETURN n, r, m